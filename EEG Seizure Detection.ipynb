{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOg4RxiPWwDTMJ33DoXQIi8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZShxKDgDlT38","executionInfo":{"status":"ok","timestamp":1768550126409,"user_tz":-60,"elapsed":935,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"615abc9f-6826-441d-f371-e6951783956c"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"k2iBpyCsvUh4","executionInfo":{"status":"ok","timestamp":1768550127096,"user_tz":-60,"elapsed":16,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/EEG/Dataset/\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bqSFrGHlT67","executionInfo":{"status":"ok","timestamp":1768550366418,"user_tz":-60,"elapsed":108,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"33e1584a-013a-4ae2-fd79-f9ea8221eecc"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/EEG/Dataset\n","\u001b[0m\u001b[01;34mA\u001b[0m/  \u001b[01;34mB\u001b[0m/  \u001b[01;34mC\u001b[0m/  \u001b[01;34mD\u001b[0m/  \u001b[01;34mE\u001b[0m/\n"]}]},{"cell_type":"code","source":["!pip install captum"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"XB0C_U5SvVXn","executionInfo":{"status":"ok","timestamp":1768549092586,"user_tz":-60,"elapsed":11586,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"c72ee384-2a26-4ace-bd2d-1b8655da018c"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting captum\n","  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from captum) (3.10.0)\n","Collecting numpy<2.0 (from captum)\n","  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from captum) (25.0)\n","Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from captum) (2.9.0+cu126)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from captum) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.20.2)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.6.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.5.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.4.9)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (3.3.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->captum) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->captum) (3.0.3)\n","Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m125.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy, captum\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pytensor 2.36.3 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","rasterio 1.5.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","tobler 0.13.0 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed captum-0.8.0 numpy-1.26.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"2665130d0b2346f4bf87dae5f4787ec1"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","import glob\n","import random\n","from dataclasses import dataclass\n","from typing import List, Tuple, Dict\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from scipy.signal import butter, filtfilt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, silhouette_score\n","from sklearn.manifold import TSNE\n","from sklearn.linear_model import LogisticRegression\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from captum.attr import IntegratedGradients\n","\n","print(\"Imports OK\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fCgyx-gNt61w","executionInfo":{"status":"ok","timestamp":1768552573804,"user_tz":-60,"elapsed":9,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"addcf583-d811-46c9-f2ac-4169d2e924e9"},"execution_count":83,"outputs":[{"output_type":"stream","name":"stdout","text":["Imports OK\n"]}]},{"cell_type":"code","source":["c_dir = \"/content/drive/MyDrive/EEG/Dataset/C\"\n","\n","files = glob.glob(os.path.join(c_dir, \"*.TXT\"))\n","\n","print(\"Files to rename:\", len(files))\n","\n","for f in files:\n","    new_name = f[:-4] + \".txt\"   # replace .TXT with .txt\n","    os.rename(f, new_name)\n","\n","print(\"Renaming completed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gn-PHM7y0o8M","executionInfo":{"status":"ok","timestamp":1768552592026,"user_tz":-60,"elapsed":61,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"fdd57502-9af3-48dc-a9e2-7c40229c28ad"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Files to rename: 0\n","Renaming completed.\n"]}]},{"cell_type":"code","source":["class Config:\n","    data_root: str = \"/content/drive/MyDrive/EEG/Dataset\"\n","    fs: float = 173.61\n","    segment_len: int = 4096\n","\n","    # Preprocessing\n","    bandpass: Tuple[float, float] = (0.5, 40.0)\n","    filter_order: int = 4\n","    standardize_per_segment: bool = True\n","\n","    # Windowing (keep as full segment by default)\n","    window_len: int = 4096\n","    window_stride: int = 4096\n","\n","    # Training\n","    seed: int = 42\n","    batch_size: int = 32\n","    lr: float = 1e-3\n","    weight_decay: float = 1e-4\n","    epochs: int = 30\n","\n","    # Splits\n","    test_size: float = 0.2\n","    val_size: float = 0.2\n","\n","    # Best model selection metric on test: \"f1\" | \"auc\" | \"accuracy\"\n","    selection_metric: str = \"f1\"\n","\n","    # Base output directory (task subfolders will be created inside)\n","    out_base: str = \"/content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined\"\n","\n","cfg = Config()\n","cfg\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_svzg1mYt6w6","executionInfo":{"status":"ok","timestamp":1768552604645,"user_tz":-60,"elapsed":11,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"1e6b6750-ad00-48e0-9bf5-5ea2404964a3"},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<__main__.Config at 0x7f82c03d34d0>"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["for s in [\"A\",\"B\",\"C\",\"D\",\"E\"]:\n","    folder = os.path.join(cfg.data_root, s)\n","    n_txt = len(glob.glob(os.path.join(folder, \"*.txt\")))\n","    n_TXT = len(glob.glob(os.path.join(folder, \"*.TXT\")))\n","    print(s, \"exists:\", os.path.isdir(folder), \"| .txt:\", n_txt, \"| .TXT:\", n_TXT)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdIFLSz-zKvn","executionInfo":{"status":"ok","timestamp":1768552620466,"user_tz":-60,"elapsed":31,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"2d7ae5c2-8069-471a-e62b-0a0cf168c946"},"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["A exists: True | .txt: 100 | .TXT: 0\n","B exists: True | .txt: 100 | .TXT: 0\n","C exists: True | .txt: 100 | .TXT: 0\n","D exists: True | .txt: 100 | .TXT: 0\n","E exists: True | .txt: 100 | .TXT: 0\n"]}]},{"cell_type":"code","source":["def set_seed(seed: int) -> None:\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","def ensure_dir(path: str) -> None:\n","    os.makedirs(path, exist_ok=True)\n","\n","def compute_metrics(y_true: np.ndarray, y_prob: np.ndarray, threshold: float = 0.5) -> Dict:\n","    y_pred = (y_prob >= threshold).astype(int)\n","    acc = accuracy_score(y_true, y_pred)\n","    f1 = f1_score(y_true, y_pred)\n","    auc = roc_auc_score(y_true, y_prob) if len(np.unique(y_true)) == 2 else float(\"nan\")\n","    cm = confusion_matrix(y_true, y_pred)\n","    return {\"accuracy\": acc, \"f1\": f1, \"auc\": auc, \"confusion_matrix\": cm}\n","\n","set_seed(cfg.seed)\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Device:\", device)\n","\n","ensure_dir(cfg.out_base)\n","print(\"Base output:\", cfg.out_base)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FE8VKE7Yt6sY","executionInfo":{"status":"ok","timestamp":1768552637842,"user_tz":-60,"elapsed":20,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"b3a5921d-2005-4e50-8abb-5649b2e5327d"},"execution_count":87,"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n","Base output: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined\n"]}]},{"cell_type":"code","source":["def bandpass_filter(x: np.ndarray, fs: float, low: float, high: float, order: int = 4) -> np.ndarray:\n","    nyq = 0.5 * fs\n","    b, a = butter(order, [low / nyq, high / nyq], btype=\"band\")\n","    return filtfilt(b, a, x).astype(np.float32)\n","\n","def zscore(x: np.ndarray, eps: float = 1e-8) -> np.ndarray:\n","    return ((x - x.mean()) / (x.std() + eps)).astype(np.float32)\n","\n","def make_windows(x: np.ndarray, window_len: int, stride: int) -> np.ndarray:\n","    if window_len == len(x) and stride == len(x):\n","        return x[None, :]\n","    windows = []\n","    for start in range(0, len(x) - window_len + 1, stride):\n","        windows.append(x[start:start + window_len])\n","    return np.stack(windows, axis=0).astype(np.float32)\n","\n","print(\"Preprocessing OK\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6PUzRLuUt6lq","executionInfo":{"status":"ok","timestamp":1768552653433,"user_tz":-60,"elapsed":37,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"afad9429-8db6-4847-8761-52ef5ef4dfbd"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing OK\n"]}]},{"cell_type":"code","source":["def gather_files(data_root: str, sets: List[str]) -> List[str]:\n","    paths = []\n","    for s in sets:\n","        paths.extend(sorted(glob.glob(os.path.join(data_root, s, \"*.txt\"))))\n","        paths.extend(sorted(glob.glob(os.path.join(data_root, s, \"*.TXT\"))))\n","    return paths\n","\n","def load_txt_signal(path: str) -> np.ndarray:\n","    return np.loadtxt(path).astype(np.float32)\n","\n","class BonnEEGDataset(Dataset):\n","    def __init__(self, cfg: Config, file_list: List[Tuple[str, int]]):\n","        self.cfg = cfg\n","        self.files = file_list\n","        self._cache = {}\n","        self.index = []\n","\n","        for i, (path, _) in enumerate(self.files):\n","            seg = self._load_and_preprocess(path)\n","            wins = make_windows(seg, cfg.window_len, cfg.window_stride)\n","            for w_idx in range(len(wins)):\n","                self.index.append((i, w_idx))\n","\n","    def _load_and_preprocess(self, path: str) -> np.ndarray:\n","        if path in self._cache:\n","            return self._cache[path]\n","\n","        x = load_txt_signal(path)\n","\n","        low, high = self.cfg.bandpass\n","        x = bandpass_filter(x, self.cfg.fs, low, high, self.cfg.filter_order)\n","\n","        if self.cfg.standardize_per_segment:\n","            x = zscore(x)\n","\n","        self._cache[path] = x\n","        return x\n","\n","    def __len__(self):\n","        return len(self.index)\n","\n","    def __getitem__(self, idx: int):\n","        file_idx, w_idx = self.index[idx]\n","        path, label = self.files[file_idx]\n","\n","        seg = self._load_and_preprocess(path)\n","        wins = make_windows(seg, self.cfg.window_len, self.cfg.window_stride)\n","        w = wins[w_idx]\n","\n","        x_t = torch.tensor(w, dtype=torch.float32).unsqueeze(0)  # (1,L)\n","        y_t = torch.tensor(label, dtype=torch.long)\n","        return x_t, y_t, path\n","\n","print(\"Dataset OK\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D26MaD0qt6Xc","executionInfo":{"status":"ok","timestamp":1768552670716,"user_tz":-60,"elapsed":32,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"8356bcf0-464b-45a8-a65e-1275177e6ef1"},"execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset OK\n"]}]},{"cell_type":"code","source":["class CNN1D(nn.Module):\n","    def __init__(self, in_ch=1, num_classes=2, feat_dim=128):\n","        super().__init__()\n","        self.backbone = nn.Sequential(\n","            nn.Conv1d(in_ch, 32, 7, padding=3),\n","            nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","            nn.MaxPool1d(2),\n","\n","            nn.Conv1d(32, 64, 5, padding=2),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.MaxPool1d(2),\n","\n","            nn.Conv1d(64, 128, 3, padding=1),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","        )\n","        self.gap = nn.AdaptiveAvgPool1d(1)\n","        self.fc_feat = nn.Linear(128, feat_dim)\n","        self.fc_out = nn.Linear(feat_dim, num_classes)\n","\n","    def extract_features(self, x):\n","        h = self.backbone(x)\n","        h = self.gap(h).squeeze(-1)\n","        f = self.fc_feat(h)\n","        return f\n","\n","    def forward(self, x):\n","        f = self.extract_features(x)\n","        return self.fc_out(F.relu(f))\n","\n","\n","class CNN_BiLSTM(nn.Module):\n","    def __init__(self, in_ch=1, num_classes=2, feat_dim=128, lstm_hidden=64):\n","        super().__init__()\n","        self.cnn = nn.Sequential(\n","            nn.Conv1d(in_ch, 32, 7, padding=3),\n","            nn.BatchNorm1d(32),\n","            nn.ReLU(),\n","            nn.MaxPool1d(4),\n","\n","            nn.Conv1d(32, 64, 5, padding=2),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(),\n","            nn.MaxPool1d(4),\n","        )\n","        self.lstm = nn.LSTM(\n","            input_size=64,\n","            hidden_size=lstm_hidden,\n","            num_layers=1,\n","            batch_first=True,\n","            bidirectional=True\n","        )\n","        self.fc_feat = nn.Linear(2 * lstm_hidden, feat_dim)\n","        self.fc_out = nn.Linear(feat_dim, num_classes)\n","\n","    def extract_features(self, x):\n","        h = self.cnn(x)\n","        h = h.transpose(1, 2)\n","        out, _ = self.lstm(h)\n","        last = out[:, -1, :]\n","        f = self.fc_feat(last)\n","        return f\n","\n","    def forward(self, x):\n","        f = self.extract_features(x)\n","        return self.fc_out(F.relu(f))\n","\n","\n","class Transformer1D(nn.Module):\n","    def __init__(self, in_ch=1, num_classes=2, feat_dim=128, d_model=128, nhead=4, num_layers=2):\n","        super().__init__()\n","        self.patch = nn.Conv1d(in_ch, d_model, kernel_size=16, stride=8, padding=8)\n","        enc_layer = nn.TransformerEncoderLayer(\n","            d_model=d_model,\n","            nhead=nhead,\n","            dim_feedforward=4 * d_model,\n","            batch_first=True\n","        )\n","        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=num_layers)\n","        self.fc_feat = nn.Linear(d_model, feat_dim)\n","        self.fc_out = nn.Linear(feat_dim, num_classes)\n","\n","    def extract_features(self, x):\n","        h = self.patch(x)\n","        h = h.transpose(1, 2)\n","        z = self.encoder(h)\n","        pooled = z.mean(dim=1)\n","        f = self.fc_feat(pooled)\n","        return f\n","\n","    def forward(self, x):\n","        f = self.extract_features(x)\n","        return self.fc_out(F.relu(f))\n","\n","print(\"Models OK\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ayIVMd3EvzwU","executionInfo":{"status":"ok","timestamp":1768552756304,"user_tz":-60,"elapsed":21,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"00dec0d2-1c46-49fd-8d1a-9158c7f61d92"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["Models OK\n"]}]},{"cell_type":"code","source":["@torch.no_grad()\n","def evaluate(model: nn.Module, loader: DataLoader, device: str) -> Dict:\n","    model.eval()\n","    y_true, y_prob = [], []\n","    for x, y, _ in loader:\n","        x = x.to(device)\n","        logits = model(x)\n","        prob = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()\n","        y_true.append(y.numpy())\n","        y_prob.append(prob)\n","    y_true = np.concatenate(y_true)\n","    y_prob = np.concatenate(y_prob)\n","    return compute_metrics(y_true, y_prob)\n","\n","def train_one_model(model, train_loader, val_loader, device, cfg, class_weights):\n","    model.to(device)\n","    opt = torch.optim.AdamW(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n","    loss_fn = nn.CrossEntropyLoss(weight=class_weights.to(device))\n","\n","    best_val = -1.0\n","    best_state = None\n","\n","    for epoch in range(1, cfg.epochs + 1):\n","        model.train()\n","        for x, y, _ in train_loader:\n","            x, y = x.to(device), y.to(device)\n","            opt.zero_grad()\n","            logits = model(x)\n","            loss = loss_fn(logits, y)\n","            loss.backward()\n","            opt.step()\n","\n","        val_metrics = evaluate(model, val_loader, device)\n","        score = val_metrics[cfg.selection_metric]\n","        print(f\"Epoch {epoch:02d} | val_{cfg.selection_metric}={score:.4f} | val_acc={val_metrics['accuracy']:.4f} | val_auc={val_metrics['auc']:.4f}\")\n","\n","        if score > best_val:\n","            best_val = score\n","            best_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}\n","\n","    model.load_state_dict(best_state)\n","    return model, best_val\n","\n","\n","# ---------- Feature extraction ----------\n","@torch.no_grad()\n","def extract_embeddings(model: nn.Module, loader: DataLoader, device: str):\n","    model.eval()\n","    feats, labels = [], []\n","    for x, y, _ in loader:\n","        x = x.to(device)\n","        f = model.extract_features(x).detach().cpu().numpy()\n","        feats.append(f)\n","        labels.append(y.numpy())\n","    return np.concatenate(feats), np.concatenate(labels)\n","\n","def linear_probe(feats: np.ndarray, labels: np.ndarray, seed: int = 42):\n","    Xtr, Xte, ytr, yte = train_test_split(feats, labels, test_size=0.3, random_state=seed, stratify=labels)\n","    clf = LogisticRegression(max_iter=2000)\n","    clf.fit(Xtr, ytr)\n","    pred = clf.predict(Xte)\n","    return {\"probe_acc\": accuracy_score(yte, pred), \"probe_f1\": f1_score(yte, pred)}\n","\n","def save_tsne_plot(z2: np.ndarray, labels: np.ndarray, title: str, out_path: str):\n","    plt.figure()\n","    plt.scatter(z2[:, 0], z2[:, 1], c=labels)\n","    plt.title(title)\n","    plt.savefig(out_path, dpi=200, bbox_inches=\"tight\")\n","    plt.close()\n","\n","\n","# ---------- XAI: IG + Occlusion ----------\n","@torch.no_grad()\n","def model_prob_class1(model: nn.Module, x: torch.Tensor) -> float:\n","    return torch.softmax(model(x), dim=1)[0, 1].item()\n","\n","def occlusion_attribution_1d(model: nn.Module, x: torch.Tensor, window: int = 128, stride: int = 64, baseline: float = 0.0) -> np.ndarray:\n","    model.eval()\n","    x = x.clone()\n","    L = x.shape[-1]\n","    base_p = model_prob_class1(model, x)\n","\n","    attr = np.zeros(L, dtype=np.float32)\n","    counts = np.zeros(L, dtype=np.float32)\n","\n","    for start in range(0, L - window + 1, stride):\n","        x_occ = x.clone()\n","        x_occ[..., start:start+window] = baseline\n","        p_occ = model_prob_class1(model, x_occ)\n","        drop = base_p - p_occ\n","        attr[start:start+window] += drop\n","        counts[start:start+window] += 1.0\n","\n","    counts[counts == 0] = 1.0\n","    attr = attr / counts\n","    attr = np.maximum(attr, 0)\n","    attr = attr / (attr.max() + 1e-8)\n","    return attr\n","\n","def deletion_insertion_curve(model: nn.Module, x: torch.Tensor, attr: np.ndarray, target_class: int = 1, steps: int = 20):\n","    model.eval()\n","    L = x.shape[-1]\n","    idx = np.argsort(-attr)\n","    baseline = torch.zeros_like(x)\n","\n","    @torch.no_grad()\n","    def prob(inp):\n","        return torch.softmax(model(inp), dim=1)[0, target_class].item()\n","\n","    del_probs = [prob(x)]\n","    ins_probs = [prob(baseline)]\n","\n","    k = max(1, L // steps)\n","    x_del = x.clone()\n","    x_ins = baseline.clone()\n","\n","    for s in range(steps):\n","        sel = idx[s*k:(s+1)*k]\n","        x_del[..., sel] = 0.0\n","        x_ins[..., sel] = x[..., sel]\n","        del_probs.append(prob(x_del))\n","        ins_probs.append(prob(x_ins))\n","\n","    return np.array(del_probs), np.array(ins_probs)\n","\n","print(\"Core helpers OK\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JVON8nJ12lRV","executionInfo":{"status":"ok","timestamp":1768552804853,"user_tz":-60,"elapsed":24,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"a1c2b175-7766-4141-9e90-a527bdb4997d"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["Core helpers OK\n"]}]},{"cell_type":"code","source":["TASKS = {\n","    \"AB_vs_E\": {\"non_seizure\": (\"A\",\"B\"), \"seizure\": (\"E\",)},\n","    \"CD_vs_E\": {\"non_seizure\": (\"C\",\"D\"), \"seizure\": (\"E\",)},\n","}\n","\n","final_summary_rows = []  # will store task-level summary for final comparison\n","\n","for task_name, task_def in TASKS.items():\n","    print(\"\\n\" + \"=\"*70)\n","    print(\"RUNNING TASK:\", task_name)\n","    print(\"=\"*70)\n","\n","    # task-specific out dir\n","    out_dir = os.path.join(cfg.out_base, task_name)\n","    ensure_dir(out_dir)\n","\n","    # Build file list\n","    non_sets = list(task_def[\"non_seizure\"])\n","    seiz_sets = list(task_def[\"seizure\"])\n","\n","    files_0 = [(p, 0) for p in gather_files(cfg.data_root, non_sets)]\n","    files_1 = [(p, 1) for p in gather_files(cfg.data_root, seiz_sets)]\n","    files = files_0 + files_1\n","\n","    if len(files) == 0:\n","        raise RuntimeError(f\"No files found for task {task_name}. Check folders/extensions.\")\n","\n","    labels = [y for _, y in files]\n","\n","    # Split\n","    train_files, test_files = train_test_split(files, test_size=cfg.test_size, random_state=cfg.seed, stratify=labels)\n","    train_labels = [y for _, y in train_files]\n","    train_files, val_files = train_test_split(train_files, test_size=cfg.val_size, random_state=cfg.seed, stratify=train_labels)\n","\n","    print(\"Counts:\", {\"train\": len(train_files), \"val\": len(val_files), \"test\": len(test_files)})\n","\n","    # Datasets/loaders\n","    train_ds = BonnEEGDataset(cfg, train_files)\n","    val_ds   = BonnEEGDataset(cfg, val_files)\n","    test_ds  = BonnEEGDataset(cfg, test_files)\n","\n","    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size, shuffle=True)\n","    val_loader   = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False)\n","    test_loader  = DataLoader(test_ds, batch_size=cfg.batch_size, shuffle=False)\n","\n","    # Class weights\n","    y_train = np.array([y for _, y in train_files])\n","    n0 = int((y_train == 0).sum()); n1 = int((y_train == 1).sum())\n","    w0 = (n0 + n1) / (2.0 * max(n0, 1))\n","    w1 = (n0 + n1) / (2.0 * max(n1, 1))\n","    class_weights = torch.tensor([w0, w1], dtype=torch.float32)\n","    print(\"Class weights:\", class_weights.tolist(), f\"(n0={n0}, n1={n1})\")\n","\n","    # Train 3 models\n","    candidates = {\n","        \"CNN1D\": CNN1D(),\n","        \"CNN_BiLSTM\": CNN_BiLSTM(),\n","        \"Transformer1D\": Transformer1D(),\n","    }\n","\n","    results = {}\n","\n","    for model_name, model in candidates.items():\n","        print(\"\\n--- Training model:\", model_name, \"| task:\", task_name)\n","        model, best_val = train_one_model(model, train_loader, val_loader, device, cfg, class_weights)\n","        test_metrics = evaluate(model, test_loader, device)\n","        print(\"TEST:\", test_metrics)\n","\n","        ckpt_path = os.path.join(out_dir, f\"{model_name}_best.pt\")\n","        torch.save(model.state_dict(), ckpt_path)\n","\n","        results[model_name] = {\"best_val\": best_val, \"test\": test_metrics, \"ckpt\": ckpt_path}\n","\n","    # Best model by selection metric on TEST\n","    best_model_name = max(results.keys(), key=lambda k: results[k][\"test\"][cfg.selection_metric])\n","    best_ckpt = results[best_model_name][\"ckpt\"]\n","\n","    print(\"\\nBEST MODEL for\", task_name, \"=\", best_model_name)\n","    print(\"Best test metrics:\", results[best_model_name][\"test\"])\n","\n","    # Save summary.txt\n","    summary_path = os.path.join(out_dir, \"summary.txt\")\n","    with open(summary_path, \"w\") as f:\n","        for m, r in results.items():\n","            f.write(f\"{m}\\n  ckpt: {r['ckpt']}\\n  best_val: {r['best_val']}\\n  test: {r['test']}\\n\\n\")\n","        f.write(f\"BEST: {best_model_name}\\n\")\n","    print(\"Saved:\", summary_path)\n","\n","    # -----------------------\n","    # Feature extraction & comparison\n","    # -----------------------\n","    print(\"\\nFEATURE EXTRACTION for\", task_name)\n","\n","    full_ds = BonnEEGDataset(cfg, files)\n","    full_loader = DataLoader(full_ds, batch_size=cfg.batch_size, shuffle=False)\n","\n","    feature_report_path = os.path.join(out_dir, \"feature_report.txt\")\n","    with open(feature_report_path, \"w\") as fr:\n","        for m in candidates.keys():\n","            # reload model\n","            if m == \"CNN1D\":\n","                model = CNN1D()\n","            elif m == \"CNN_BiLSTM\":\n","                model = CNN_BiLSTM()\n","            else:\n","                model = Transformer1D()\n","\n","            model.load_state_dict(torch.load(os.path.join(out_dir, f\"{m}_best.pt\"), map_location=\"cpu\"))\n","            model.to(device).eval()\n","\n","            feats, y_np = extract_embeddings(model, full_loader, device)\n","\n","            sil = silhouette_score(feats, y_np) if len(np.unique(y_np)) == 2 else float(\"nan\")\n","            probe = linear_probe(feats, y_np, cfg.seed)\n","\n","            msg = f\"{m}\\n  emb_shape={feats.shape}\\n  silhouette={sil}\\n  linear_probe={probe}\\n\"\n","            print(msg)\n","            fr.write(msg + \"\\n\")\n","\n","            tsne = TSNE(n_components=2, perplexity=20, random_state=cfg.seed)\n","            z2 = tsne.fit_transform(feats)\n","            tsne_path = os.path.join(out_dir, f\"tsne_{m}.png\")\n","            save_tsne_plot(z2, y_np, f\"t-SNE Embeddings: {m} ({task_name})\", tsne_path)\n","            print(\"Saved:\", tsne_path)\n","\n","    print(\"Saved feature report:\", feature_report_path)\n","\n","    # -----------------------\n","    # XAI on best model: IG + Occlusion\n","    # -----------------------\n","    print(\"\\nXAI for best model (IG + Occlusion):\", best_model_name, \"| task:\", task_name)\n","\n","    # load best model\n","    if best_model_name == \"CNN1D\":\n","        best_model = CNN1D()\n","    elif best_model_name == \"CNN_BiLSTM\":\n","        best_model = CNN_BiLSTM()\n","    else:\n","        best_model = Transformer1D()\n","\n","    best_model.load_state_dict(torch.load(best_ckpt, map_location=\"cpu\"))\n","    best_model.to(device).eval()\n","\n","    ig = IntegratedGradients(best_model)\n","\n","    # sample explanations from TEST\n","    xai_ds = BonnEEGDataset(cfg, test_files)\n","    xai_loader = DataLoader(xai_ds, batch_size=1, shuffle=True)\n","\n","    samples = []\n","    for x, y, path in xai_loader:\n","        samples.append((x.to(device), int(y.item()), path[0]))\n","        if len(samples) >= 20:   # more stable than 6\n","            break\n","\n","    xai_rows = []\n","    for i, (x, y, p) in enumerate(samples):\n","        # IG\n","        ig_attr = ig.attribute(x, target=1, baselines=torch.zeros_like(x))\n","        ig_attr = ig_attr.squeeze().detach().cpu().numpy()\n","        ig_attr = np.abs(ig_attr)\n","        ig_attr = ig_attr / (ig_attr.max() + 1e-8)\n","\n","        del_ig, ins_ig = deletion_insertion_curve(best_model, x, ig_attr, target_class=1, steps=20)\n","\n","        # Occlusion\n","        occ_attr = occlusion_attribution_1d(best_model, x, window=128, stride=64, baseline=0.0)\n","        del_occ, ins_occ = deletion_insertion_curve(best_model, x, occ_attr, target_class=1, steps=20)\n","\n","        xai_rows.append({\n","            \"sample\": i, \"label\": y, \"path\": p,\n","            \"IG_deletion_auc\": float(np.trapz(del_ig)),\n","            \"IG_insertion_auc\": float(np.trapz(ins_ig)),\n","            \"OCC_deletion_auc\": float(np.trapz(del_occ)),\n","            \"OCC_insertion_auc\": float(np.trapz(ins_occ)),\n","        })\n","\n","        # Save attribution plots (optional but good for report)\n","        sig = x.squeeze().detach().cpu().numpy()\n","\n","        plt.figure(); plt.plot(sig); plt.title(f\"Signal sample={i} label={y} ({task_name})\")\n","        plt.savefig(os.path.join(out_dir, f\"xai_signal_{i}.png\"), dpi=200, bbox_inches=\"tight\"); plt.close()\n","\n","        plt.figure(); plt.plot(ig_attr); plt.title(f\"Integrated Gradients sample={i} ({task_name})\")\n","        plt.savefig(os.path.join(out_dir, f\"xai_ig_attr_{i}.png\"), dpi=200, bbox_inches=\"tight\"); plt.close()\n","\n","        plt.figure(); plt.plot(occ_attr); plt.title(f\"Occlusion Attribution sample={i} ({task_name})\")\n","        plt.savefig(os.path.join(out_dir, f\"xai_occ_attr_{i}.png\"), dpi=200, bbox_inches=\"tight\"); plt.close()\n","\n","    # Aggregate XAI\n","    ig_del = float(np.mean([r[\"IG_deletion_auc\"] for r in xai_rows]))\n","    ig_ins = float(np.mean([r[\"IG_insertion_auc\"] for r in xai_rows]))\n","    occ_del = float(np.mean([r[\"OCC_deletion_auc\"] for r in xai_rows]))\n","    occ_ins = float(np.mean([r[\"OCC_insertion_auc\"] for r in xai_rows]))\n","\n","    if (occ_del < ig_del) and (occ_ins > ig_ins):\n","        xai_winner = \"Occlusion\"\n","    elif (ig_del < occ_del) and (ig_ins > occ_ins):\n","        xai_winner = \"Integrated Gradients\"\n","    else:\n","        xai_winner = \"Mixed\"\n","\n","    print(\"Aggregate faithfulness:\")\n","    print(\"IG   del_auc (lower better):\", ig_del, \"| ins_auc (higher better):\", ig_ins)\n","    print(\"OCC  del_auc (lower better):\", occ_del, \"| ins_auc (higher better):\", occ_ins)\n","    print(\"Winner XAI:\", xai_winner)\n","\n","    # Save XAI report\n","    xai_report_path = os.path.join(out_dir, \"xai_report.txt\")\n","    with open(xai_report_path, \"w\") as f:\n","        for r in xai_rows:\n","            f.write(str(r) + \"\\n\")\n","        f.write(\"\\nAGGREGATE\\n\")\n","        f.write(f\"IG_del={ig_del}, IG_ins={ig_ins}\\n\")\n","        f.write(f\"OCC_del={occ_del}, OCC_ins={occ_ins}\\n\")\n","        f.write(f\"WINNER_XAI={xai_winner}\\n\")\n","    print(\"Saved:\", xai_report_path)\n","\n","    # -----------------------\n","    # Collect task-level summary row for final comparison table\n","    # -----------------------\n","    best_test = results[best_model_name][\"test\"]\n","    final_summary_rows.append({\n","        \"task\": task_name,\n","        \"non_seizure_sets\": str(tuple(non_sets)),\n","        \"seizure_sets\": str(tuple(seiz_sets)),\n","        \"best_model\": best_model_name,\n","        \"best_test_accuracy\": best_test[\"accuracy\"],\n","        \"best_test_f1\": best_test[\"f1\"],\n","        \"best_test_auc\": best_test[\"auc\"],\n","        \"xai_winner\": xai_winner,\n","        \"IG_del_auc\": ig_del,\n","        \"IG_ins_auc\": ig_ins,\n","        \"OCC_del_auc\": occ_del,\n","        \"OCC_ins_auc\": occ_ins,\n","        \"out_dir\": out_dir\n","    })\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"ALL TASKS COMPLETED\")\n","print(\"=\"*70)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7HBrlMuQ2odF","executionInfo":{"status":"ok","timestamp":1768553047046,"user_tz":-60,"elapsed":215647,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"a200293f-422e-4a11-d716-25a85b82d982"},"execution_count":92,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","RUNNING TASK: AB_vs_E\n","======================================================================\n","Counts: {'train': 192, 'val': 48, 'test': 60}\n","Class weights: [0.75, 1.5] (n0=128, n1=64)\n","\n","--- Training model: CNN1D | task: AB_vs_E\n","Epoch 01 | val_f1=0.5079 | val_acc=0.3542 | val_auc=0.8789\n","Epoch 02 | val_f1=0.5000 | val_acc=0.3333 | val_auc=0.8926\n","Epoch 03 | val_f1=0.5000 | val_acc=0.3333 | val_auc=0.9160\n","Epoch 04 | val_f1=0.5000 | val_acc=0.3333 | val_auc=0.9453\n","Epoch 05 | val_f1=0.5000 | val_acc=0.3333 | val_auc=0.9629\n","Epoch 06 | val_f1=0.5000 | val_acc=0.3333 | val_auc=0.9844\n","Epoch 07 | val_f1=0.5246 | val_acc=0.3958 | val_auc=0.9961\n","Epoch 08 | val_f1=0.5246 | val_acc=0.3958 | val_auc=1.0000\n","Epoch 09 | val_f1=0.7111 | val_acc=0.7292 | val_auc=1.0000\n","Epoch 10 | val_f1=0.9412 | val_acc=0.9583 | val_auc=1.0000\n","Epoch 11 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 12 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 13 | val_f1=0.8649 | val_acc=0.8958 | val_auc=1.0000\n","Epoch 14 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 15 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 16 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 17 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 18 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 19 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 20 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 21 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 22 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 23 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 24 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 25 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 26 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 27 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 28 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 29 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 30 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","TEST: {'accuracy': 0.9666666666666667, 'f1': 0.95, 'auc': 0.99875, 'confusion_matrix': array([[39,  1],\n","       [ 1, 19]])}\n","\n","--- Training model: CNN_BiLSTM | task: AB_vs_E\n","Epoch 01 | val_f1=0.2727 | val_acc=0.6667 | val_auc=0.7812\n","Epoch 02 | val_f1=0.6857 | val_acc=0.7708 | val_auc=0.8438\n","Epoch 03 | val_f1=0.5926 | val_acc=0.5417 | val_auc=0.9219\n","Epoch 04 | val_f1=0.5161 | val_acc=0.3750 | val_auc=0.9219\n","Epoch 05 | val_f1=0.7619 | val_acc=0.7917 | val_auc=0.9590\n","Epoch 06 | val_f1=0.8824 | val_acc=0.9167 | val_auc=0.9746\n","Epoch 07 | val_f1=0.9032 | val_acc=0.9375 | val_auc=0.9746\n","Epoch 08 | val_f1=0.9143 | val_acc=0.9375 | val_auc=0.9922\n","Epoch 09 | val_f1=0.5333 | val_acc=0.4167 | val_auc=0.9707\n","Epoch 10 | val_f1=0.9143 | val_acc=0.9375 | val_auc=0.9922\n","Epoch 11 | val_f1=0.9375 | val_acc=0.9583 | val_auc=0.9941\n","Epoch 12 | val_f1=0.9697 | val_acc=0.9792 | val_auc=0.9961\n","Epoch 13 | val_f1=0.9697 | val_acc=0.9792 | val_auc=0.9980\n","Epoch 14 | val_f1=0.8889 | val_acc=0.9167 | val_auc=0.9844\n","Epoch 15 | val_f1=0.9032 | val_acc=0.9375 | val_auc=0.9863\n","Epoch 16 | val_f1=0.8667 | val_acc=0.9167 | val_auc=0.9844\n","Epoch 17 | val_f1=0.9032 | val_acc=0.9375 | val_auc=0.9883\n","Epoch 18 | val_f1=0.8667 | val_acc=0.9167 | val_auc=0.9922\n","Epoch 19 | val_f1=0.8750 | val_acc=0.9167 | val_auc=0.9922\n","Epoch 20 | val_f1=0.9375 | val_acc=0.9583 | val_auc=0.9922\n","Epoch 21 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9980\n","Epoch 22 | val_f1=0.9697 | val_acc=0.9792 | val_auc=0.9961\n","Epoch 23 | val_f1=0.9697 | val_acc=0.9792 | val_auc=0.9961\n","Epoch 24 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 25 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 26 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 27 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 28 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 29 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 30 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9980\n","TEST: {'accuracy': 0.9333333333333333, 'f1': 0.8888888888888888, 'auc': 0.9662499999999999, 'confusion_matrix': array([[40,  0],\n","       [ 4, 16]])}\n","\n","--- Training model: Transformer1D | task: AB_vs_E\n","Epoch 01 | val_f1=0.0000 | val_acc=0.6667 | val_auc=0.9395\n","Epoch 02 | val_f1=0.3158 | val_acc=0.7292 | val_auc=0.9297\n","Epoch 03 | val_f1=0.8750 | val_acc=0.9167 | val_auc=0.9453\n","Epoch 04 | val_f1=0.7857 | val_acc=0.8750 | val_auc=0.9824\n","Epoch 05 | val_f1=0.8966 | val_acc=0.9375 | val_auc=0.9941\n","Epoch 06 | val_f1=0.9143 | val_acc=0.9375 | val_auc=1.0000\n","Epoch 07 | val_f1=0.9697 | val_acc=0.9792 | val_auc=0.9980\n","Epoch 08 | val_f1=0.8421 | val_acc=0.8750 | val_auc=0.9922\n","Epoch 09 | val_f1=0.8571 | val_acc=0.9167 | val_auc=1.0000\n","Epoch 10 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 11 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 12 | val_f1=0.9412 | val_acc=0.9583 | val_auc=1.0000\n","Epoch 13 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 14 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 15 | val_f1=0.9412 | val_acc=0.9583 | val_auc=1.0000\n","Epoch 16 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 17 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 18 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 19 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 20 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 21 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 22 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 23 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 24 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 25 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 26 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 27 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 28 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 29 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 30 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","TEST: {'accuracy': 0.9833333333333333, 'f1': 0.9743589743589743, 'auc': 1.0, 'confusion_matrix': array([[40,  0],\n","       [ 1, 19]])}\n","\n","BEST MODEL for AB_vs_E = Transformer1D\n","Best test metrics: {'accuracy': 0.9833333333333333, 'f1': 0.9743589743589743, 'auc': 1.0, 'confusion_matrix': array([[40,  0],\n","       [ 1, 19]])}\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/AB_vs_E/summary.txt\n","\n","FEATURE EXTRACTION for AB_vs_E\n","CNN1D\n","  emb_shape=(300, 128)\n","  silhouette=0.7995028495788574\n","  linear_probe={'probe_acc': 0.9888888888888889, 'probe_f1': 0.9830508474576272}\n","\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/AB_vs_E/tsne_CNN1D.png\n","CNN_BiLSTM\n","  emb_shape=(300, 128)\n","  silhouette=0.81369549036026\n","  linear_probe={'probe_acc': 0.9555555555555556, 'probe_f1': 0.9310344827586207}\n","\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/AB_vs_E/tsne_CNN_BiLSTM.png\n","Transformer1D\n","  emb_shape=(300, 128)\n","  silhouette=0.8821537494659424\n","  linear_probe={'probe_acc': 0.9888888888888889, 'probe_f1': 0.9830508474576272}\n","\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/AB_vs_E/tsne_Transformer1D.png\n","Saved feature report: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/AB_vs_E/feature_report.txt\n","\n","XAI for best model (IG + Occlusion): Transformer1D | task: AB_vs_E\n","Aggregate faithfulness:\n","IG   del_auc (lower better): 19.356909416487905 | ins_auc (higher better): 9.340501567954197\n","OCC  del_auc (lower better): 18.90896888623247 | ins_auc (higher better): 18.96305566765368\n","Winner XAI: Occlusion\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/AB_vs_E/xai_report.txt\n","\n","======================================================================\n","RUNNING TASK: CD_vs_E\n","======================================================================\n","Counts: {'train': 192, 'val': 48, 'test': 60}\n","Class weights: [0.75, 1.5] (n0=128, n1=64)\n","\n","--- Training model: CNN1D | task: CD_vs_E\n","Epoch 01 | val_f1=0.8148 | val_acc=0.8958 | val_auc=0.9492\n","Epoch 02 | val_f1=0.4762 | val_acc=0.7708 | val_auc=0.9668\n","Epoch 03 | val_f1=0.8966 | val_acc=0.9375 | val_auc=0.9707\n","Epoch 04 | val_f1=0.8966 | val_acc=0.9375 | val_auc=0.9707\n","Epoch 05 | val_f1=0.9333 | val_acc=0.9583 | val_auc=0.9766\n","Epoch 06 | val_f1=0.7778 | val_acc=0.8333 | val_auc=0.9746\n","Epoch 07 | val_f1=0.8485 | val_acc=0.8958 | val_auc=0.9863\n","Epoch 08 | val_f1=0.9333 | val_acc=0.9583 | val_auc=0.9902\n","Epoch 09 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9961\n","Epoch 10 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 11 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 12 | val_f1=0.9333 | val_acc=0.9583 | val_auc=1.0000\n","Epoch 13 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 14 | val_f1=0.8966 | val_acc=0.9375 | val_auc=1.0000\n","Epoch 15 | val_f1=0.8148 | val_acc=0.8958 | val_auc=1.0000\n","Epoch 16 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 17 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 18 | val_f1=0.7692 | val_acc=0.8750 | val_auc=1.0000\n","Epoch 19 | val_f1=0.7273 | val_acc=0.7500 | val_auc=1.0000\n","Epoch 20 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 21 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 22 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 23 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 24 | val_f1=0.9143 | val_acc=0.9375 | val_auc=1.0000\n","Epoch 25 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 26 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 27 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 28 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","Epoch 29 | val_f1=0.9333 | val_acc=0.9583 | val_auc=1.0000\n","Epoch 30 | val_f1=1.0000 | val_acc=1.0000 | val_auc=1.0000\n","TEST: {'accuracy': 0.9666666666666667, 'f1': 0.9473684210526315, 'auc': 0.9824999999999999, 'confusion_matrix': array([[40,  0],\n","       [ 2, 18]])}\n","\n","--- Training model: CNN_BiLSTM | task: CD_vs_E\n","Epoch 01 | val_f1=0.5143 | val_acc=0.6458 | val_auc=0.6719\n","Epoch 02 | val_f1=0.1176 | val_acc=0.6875 | val_auc=0.6758\n","Epoch 03 | val_f1=0.3158 | val_acc=0.7292 | val_auc=0.7715\n","Epoch 04 | val_f1=0.7200 | val_acc=0.8542 | val_auc=0.8438\n","Epoch 05 | val_f1=0.4000 | val_acc=0.7500 | val_auc=0.7793\n","Epoch 06 | val_f1=0.7000 | val_acc=0.7500 | val_auc=0.8828\n","Epoch 07 | val_f1=0.3158 | val_acc=0.7292 | val_auc=0.6895\n","Epoch 08 | val_f1=0.6154 | val_acc=0.7917 | val_auc=0.6953\n","Epoch 09 | val_f1=0.5957 | val_acc=0.6042 | val_auc=0.7363\n","Epoch 10 | val_f1=0.5714 | val_acc=0.6875 | val_auc=0.7402\n","Epoch 11 | val_f1=0.5185 | val_acc=0.7292 | val_auc=0.7441\n","Epoch 12 | val_f1=0.5385 | val_acc=0.7500 | val_auc=0.7402\n","Epoch 13 | val_f1=0.4667 | val_acc=0.6667 | val_auc=0.7598\n","Epoch 14 | val_f1=0.6667 | val_acc=0.7917 | val_auc=0.7773\n","Epoch 15 | val_f1=0.6842 | val_acc=0.7500 | val_auc=0.7891\n","Epoch 16 | val_f1=0.7097 | val_acc=0.8125 | val_auc=0.8066\n","Epoch 17 | val_f1=0.7500 | val_acc=0.8333 | val_auc=0.8242\n","Epoch 18 | val_f1=0.8125 | val_acc=0.8750 | val_auc=0.8457\n","Epoch 19 | val_f1=0.7778 | val_acc=0.8333 | val_auc=0.8809\n","Epoch 20 | val_f1=0.8125 | val_acc=0.8750 | val_auc=0.9277\n","Epoch 21 | val_f1=0.7027 | val_acc=0.7708 | val_auc=0.8730\n","Epoch 22 | val_f1=0.7692 | val_acc=0.8750 | val_auc=0.9355\n","Epoch 23 | val_f1=0.7273 | val_acc=0.8125 | val_auc=0.9102\n","Epoch 24 | val_f1=0.8750 | val_acc=0.9167 | val_auc=0.9531\n","Epoch 25 | val_f1=0.7568 | val_acc=0.8125 | val_auc=0.9473\n","Epoch 26 | val_f1=0.7200 | val_acc=0.8542 | val_auc=0.8828\n","Epoch 27 | val_f1=0.6857 | val_acc=0.7708 | val_auc=0.9102\n","Epoch 28 | val_f1=0.7742 | val_acc=0.8542 | val_auc=0.9414\n","Epoch 29 | val_f1=0.7179 | val_acc=0.7708 | val_auc=0.9043\n","Epoch 30 | val_f1=0.8000 | val_acc=0.8750 | val_auc=0.9258\n","TEST: {'accuracy': 0.95, 'f1': 0.918918918918919, 'auc': 0.9612499999999999, 'confusion_matrix': array([[40,  0],\n","       [ 3, 17]])}\n","\n","--- Training model: Transformer1D | task: CD_vs_E\n","Epoch 01 | val_f1=0.0000 | val_acc=0.6667 | val_auc=0.8457\n","Epoch 02 | val_f1=0.6667 | val_acc=0.8333 | val_auc=0.9062\n","Epoch 03 | val_f1=0.8125 | val_acc=0.8750 | val_auc=0.9297\n","Epoch 04 | val_f1=0.8000 | val_acc=0.8333 | val_auc=0.9531\n","Epoch 05 | val_f1=0.8667 | val_acc=0.9167 | val_auc=0.9590\n","Epoch 06 | val_f1=0.8667 | val_acc=0.9167 | val_auc=0.9805\n","Epoch 07 | val_f1=0.8485 | val_acc=0.8958 | val_auc=0.9863\n","Epoch 08 | val_f1=0.8824 | val_acc=0.9167 | val_auc=0.9902\n","Epoch 09 | val_f1=0.9375 | val_acc=0.9583 | val_auc=0.9922\n","Epoch 10 | val_f1=0.9143 | val_acc=0.9375 | val_auc=0.9902\n","Epoch 11 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9961\n","Epoch 12 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9980\n","Epoch 13 | val_f1=0.8649 | val_acc=0.8958 | val_auc=0.9922\n","Epoch 14 | val_f1=0.8571 | val_acc=0.9167 | val_auc=0.9980\n","Epoch 15 | val_f1=0.8649 | val_acc=0.8958 | val_auc=0.9980\n","Epoch 16 | val_f1=0.9333 | val_acc=0.9583 | val_auc=0.9922\n","Epoch 17 | val_f1=0.9091 | val_acc=0.9375 | val_auc=0.9883\n","Epoch 18 | val_f1=0.8571 | val_acc=0.8958 | val_auc=0.9863\n","Epoch 19 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9980\n","Epoch 20 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9922\n","Epoch 21 | val_f1=0.9412 | val_acc=0.9583 | val_auc=0.9980\n","Epoch 22 | val_f1=0.9375 | val_acc=0.9583 | val_auc=0.9980\n","Epoch 23 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 24 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 25 | val_f1=0.9677 | val_acc=0.9792 | val_auc=0.9980\n","Epoch 26 | val_f1=0.8649 | val_acc=0.8958 | val_auc=0.9980\n","Epoch 27 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 28 | val_f1=0.9143 | val_acc=0.9375 | val_auc=0.9980\n","Epoch 29 | val_f1=0.9697 | val_acc=0.9792 | val_auc=1.0000\n","Epoch 30 | val_f1=0.9677 | val_acc=0.9792 | val_auc=1.0000\n","TEST: {'accuracy': 0.9333333333333333, 'f1': 0.8888888888888888, 'auc': 0.98375, 'confusion_matrix': array([[40,  0],\n","       [ 4, 16]])}\n","\n","BEST MODEL for CD_vs_E = CNN1D\n","Best test metrics: {'accuracy': 0.9666666666666667, 'f1': 0.9473684210526315, 'auc': 0.9824999999999999, 'confusion_matrix': array([[40,  0],\n","       [ 2, 18]])}\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/CD_vs_E/summary.txt\n","\n","FEATURE EXTRACTION for CD_vs_E\n","CNN1D\n","  emb_shape=(300, 128)\n","  silhouette=0.7071604132652283\n","  linear_probe={'probe_acc': 0.9777777777777777, 'probe_f1': 0.9655172413793104}\n","\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/CD_vs_E/tsne_CNN1D.png\n","CNN_BiLSTM\n","  emb_shape=(300, 128)\n","  silhouette=0.4974000155925751\n","  linear_probe={'probe_acc': 0.9333333333333333, 'probe_f1': 0.8928571428571429}\n","\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/CD_vs_E/tsne_CNN_BiLSTM.png\n","Transformer1D\n","  emb_shape=(300, 128)\n","  silhouette=0.7633817195892334\n","  linear_probe={'probe_acc': 0.9555555555555556, 'probe_f1': 0.9285714285714286}\n","\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/CD_vs_E/tsne_Transformer1D.png\n","Saved feature report: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/CD_vs_E/feature_report.txt\n","\n","XAI for best model (IG + Occlusion): CNN1D | task: CD_vs_E\n","Aggregate faithfulness:\n","IG   del_auc (lower better): 7.47588459562382 | ins_auc (higher better): 14.425310370119854\n","OCC  del_auc (lower better): 1.4936206086162365 | ins_auc (higher better): 2.5209635579617684\n","Winner XAI: Mixed\n","Saved: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/CD_vs_E/xai_report.txt\n","\n","======================================================================\n","ALL TASKS COMPLETED\n","======================================================================\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.DataFrame(final_summary_rows)\n","df = df.sort_values(by=[\"task\"]).reset_index(drop=True)\n","\n","display(df)\n","\n","csv_path = os.path.join(cfg.out_base, \"FINAL_COMPARISON_TABLE.csv\")\n","df.to_csv(csv_path, index=False)\n","print(\"Saved final comparison table to:\", csv_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212},"id":"eUZC9xXw-iry","executionInfo":{"status":"ok","timestamp":1768553070115,"user_tz":-60,"elapsed":83,"user":{"displayName":"Injamamul Haque Alve","userId":"16282175977952410711"}},"outputId":"93b65c91-d926-432f-a0e0-965edafd9ca1"},"execution_count":93,"outputs":[{"output_type":"display_data","data":{"text/plain":["      task non_seizure_sets seizure_sets     best_model  best_test_accuracy  \\\n","0  AB_vs_E       ('A', 'B')       ('E',)  Transformer1D            0.983333   \n","1  CD_vs_E       ('C', 'D')       ('E',)          CNN1D            0.966667   \n","\n","   best_test_f1  best_test_auc xai_winner  IG_del_auc  IG_ins_auc  \\\n","0      0.974359         1.0000  Occlusion   19.356909    9.340502   \n","1      0.947368         0.9825      Mixed    7.475885   14.425310   \n","\n","   OCC_del_auc  OCC_ins_auc                                            out_dir  \n","0    18.908969    18.963056  /content/drive/MyDrive/EEG/Outputs_Bonn_Projec...  \n","1     1.493621     2.520964  /content/drive/MyDrive/EEG/Outputs_Bonn_Projec...  "],"text/html":["\n","  <div id=\"df-8b275c6a-ffdd-43f6-9d5f-ffdf127277d0\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>task</th>\n","      <th>non_seizure_sets</th>\n","      <th>seizure_sets</th>\n","      <th>best_model</th>\n","      <th>best_test_accuracy</th>\n","      <th>best_test_f1</th>\n","      <th>best_test_auc</th>\n","      <th>xai_winner</th>\n","      <th>IG_del_auc</th>\n","      <th>IG_ins_auc</th>\n","      <th>OCC_del_auc</th>\n","      <th>OCC_ins_auc</th>\n","      <th>out_dir</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AB_vs_E</td>\n","      <td>('A', 'B')</td>\n","      <td>('E',)</td>\n","      <td>Transformer1D</td>\n","      <td>0.983333</td>\n","      <td>0.974359</td>\n","      <td>1.0000</td>\n","      <td>Occlusion</td>\n","      <td>19.356909</td>\n","      <td>9.340502</td>\n","      <td>18.908969</td>\n","      <td>18.963056</td>\n","      <td>/content/drive/MyDrive/EEG/Outputs_Bonn_Projec...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>CD_vs_E</td>\n","      <td>('C', 'D')</td>\n","      <td>('E',)</td>\n","      <td>CNN1D</td>\n","      <td>0.966667</td>\n","      <td>0.947368</td>\n","      <td>0.9825</td>\n","      <td>Mixed</td>\n","      <td>7.475885</td>\n","      <td>14.425310</td>\n","      <td>1.493621</td>\n","      <td>2.520964</td>\n","      <td>/content/drive/MyDrive/EEG/Outputs_Bonn_Projec...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b275c6a-ffdd-43f6-9d5f-ffdf127277d0')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8b275c6a-ffdd-43f6-9d5f-ffdf127277d0 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8b275c6a-ffdd-43f6-9d5f-ffdf127277d0');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_2ee3d3a3-240e-4e00-a5fd-ee0d64cdae2d\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2ee3d3a3-240e-4e00-a5fd-ee0d64cdae2d button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"task\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"CD_vs_E\",\n          \"AB_vs_E\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"non_seizure_sets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"('C', 'D')\",\n          \"('A', 'B')\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"seizure_sets\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"('E',)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"CNN1D\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_test_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01178511301977575,\n        \"min\": 0.9666666666666667,\n        \"max\": 0.9833333333333333,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9666666666666667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_test_f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.019085203270891995,\n        \"min\": 0.9473684210526315,\n        \"max\": 0.9743589743589743,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9473684210526315\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"best_test_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.012374368670764632,\n        \"min\": 0.9824999999999999,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.9824999999999999\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xai_winner\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Mixed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IG_del_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.401153218278681,\n        \"min\": 7.47588459562382,\n        \"max\": 19.356909416487905,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7.47588459562382\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IG_ins_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.595502785048382,\n        \"min\": 9.340501567954197,\n        \"max\": 14.425310370119854,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          14.425310370119854\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OCC_del_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.314510863827898,\n        \"min\": 1.4936206086162365,\n        \"max\": 18.90896888623247,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.4936206086162365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OCC_ins_auc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.626314827656978,\n        \"min\": 2.5209635579617684,\n        \"max\": 18.96305566765368,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.5209635579617684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"out_dir\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"/content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/CD_vs_E\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saved final comparison table to: /content/drive/MyDrive/EEG/Outputs_Bonn_Project_Combined/FINAL_COMPARISON_TABLE.csv\n"]}]}]}